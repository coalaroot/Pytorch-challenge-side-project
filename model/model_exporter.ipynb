{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelcahyawijaya/htdocs/python/onnx-tensorflow/onnx_tf/common/__init__.py:87: UserWarning: FrontendHandler.get_outputs_names is deprecated. It will be removed in future release.. Use node.outputs instead.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch.onnx\n",
    "import onnx\n",
    "import warnings\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools.import_pb_to_tensorboard import import_to_tensorboard\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.contrib.lite.python.lite import TFLiteConverter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    0: 'NINE',\n",
    "    1: 'ZERO',\n",
    "    2: 'SEVEN',\n",
    "    3: 'SIX',\n",
    "    4: 'ONE',\n",
    "    5: 'EIGHT',\n",
    "    6: 'FOUR',\n",
    "    7: 'THREE',\n",
    "    8: 'TWO',\n",
    "    9: 'FIVE', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ONNX_ML\"] = \"1\"\n",
    "warnings.filterwarnings('ignore') # Ignore all the warning messages in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64 at 0x12E8874A8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.open('test.jpg').convert('L')\n",
    "display(img) # show the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the CNN architecture without Dropout layer\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(1, 8, 3, padding=1)      \n",
    "        self.conv1_2 = nn.Conv2d(8, 16, 3, padding=1)      \n",
    "        self.conv1_3 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(2) \n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(32, 40, 3, padding=1)      \n",
    "        self.conv2_2 = nn.Conv2d(40, 48, 3, padding=1)      \n",
    "        self.conv2_3 = nn.Conv2d(48, 64, 3, padding=1)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(64, 72, 3, padding=1)      \n",
    "        self.conv3_2 = nn.Conv2d(72, 80, 3, padding=1)      \n",
    "        self.conv3_3 = nn.Conv2d(80, 96, 3, padding=1)\n",
    "        \n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(96, 128, 3, padding=1)      \n",
    "        self.conv4_2 = nn.Conv2d(128, 192, 3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(192, 256, 3, padding=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 10)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 64x64x1 => 32x32x8\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = F.relu(self.conv1_3(x))\n",
    "        x = F.relu(self.pool1(x))\n",
    "        \n",
    "        # 32x32x8 => 16x16x16\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = F.relu(self.conv2_3(x))\n",
    "        x = F.relu(self.pool2(x))\n",
    "        \n",
    "        # 16x16x16 => 8x8x32\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = F.relu(self.pool3(x))\n",
    "        \n",
    "        # 8x8x32 => 8x8x256\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "\n",
    "        # Reduce Mean & Linear\n",
    "        x = torch.mean(torch.mean(x, dim=-1), dim=-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1_1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2_1): Conv2d(32, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_2): Conv2d(40, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_3): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3_1): Conv2d(64, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_2): Conv2d(72, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_3): Conv2d(80, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4_1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_3): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('./model_sl_3968.pt', map_location=lambda storage, location: storage))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ -3.2384,  32.9433,  -6.1564, -18.4737,  -2.4728,   0.2746,  -1.5060,\n",
       "          -14.4440, -26.7159,  -7.6219]], grad_fn=<ThAddmmBackward>), 'ZERO')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test predict\n",
    "x = torch.from_numpy(np.expand_dims(np.expand_dims(np.asarray(img, dtype=np.float32), axis=0), axis=0))\n",
    "y = model(x)\n",
    "\n",
    "y_idx = torch.argmax(y)\n",
    "y, label_dict[int(y_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dummy tensor for defining input size\n",
    "dummy_input = torch.randn(1, 1, 64, 64)\n",
    "\n",
    "# Invoke export\n",
    "torch.onnx.export(model, dummy_input, \"sign_lang_net.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import to Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onnx.load('sign_lang_net.onnx') # Load the ONNX file\n",
    "tf_rep = prepare(model) # Import the ONNX model to Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0']\n",
      "-----\n",
      "['63']\n",
      "-----\n",
      "{'1': <tf.Tensor 'Const:0' shape=(8, 1, 3, 3) dtype=float32>, '2': <tf.Tensor 'Const_1:0' shape=(8,) dtype=float32>, '3': <tf.Tensor 'Const_2:0' shape=(16, 8, 3, 3) dtype=float32>, '4': <tf.Tensor 'Const_3:0' shape=(16,) dtype=float32>, '5': <tf.Tensor 'Const_4:0' shape=(32, 16, 3, 3) dtype=float32>, '6': <tf.Tensor 'Const_5:0' shape=(32,) dtype=float32>, '7': <tf.Tensor 'Const_6:0' shape=(40, 32, 3, 3) dtype=float32>, '8': <tf.Tensor 'Const_7:0' shape=(40,) dtype=float32>, '9': <tf.Tensor 'Const_8:0' shape=(48, 40, 3, 3) dtype=float32>, '10': <tf.Tensor 'Const_9:0' shape=(48,) dtype=float32>, '11': <tf.Tensor 'Const_10:0' shape=(64, 48, 3, 3) dtype=float32>, '12': <tf.Tensor 'Const_11:0' shape=(64,) dtype=float32>, '13': <tf.Tensor 'Const_12:0' shape=(72, 64, 3, 3) dtype=float32>, '14': <tf.Tensor 'Const_13:0' shape=(72,) dtype=float32>, '15': <tf.Tensor 'Const_14:0' shape=(80, 72, 3, 3) dtype=float32>, '16': <tf.Tensor 'Const_15:0' shape=(80,) dtype=float32>, '17': <tf.Tensor 'Const_16:0' shape=(96, 80, 3, 3) dtype=float32>, '18': <tf.Tensor 'Const_17:0' shape=(96,) dtype=float32>, '19': <tf.Tensor 'Const_18:0' shape=(128, 96, 3, 3) dtype=float32>, '20': <tf.Tensor 'Const_19:0' shape=(128,) dtype=float32>, '21': <tf.Tensor 'Const_20:0' shape=(192, 128, 3, 3) dtype=float32>, '22': <tf.Tensor 'Const_21:0' shape=(192,) dtype=float32>, '23': <tf.Tensor 'Const_22:0' shape=(256, 192, 3, 3) dtype=float32>, '24': <tf.Tensor 'Const_23:0' shape=(256,) dtype=float32>, '25': <tf.Tensor 'Const_24:0' shape=(1024, 256) dtype=float32>, '26': <tf.Tensor 'Const_25:0' shape=(1024,) dtype=float32>, '27': <tf.Tensor 'Const_26:0' shape=(10, 1024) dtype=float32>, '28': <tf.Tensor 'Const_27:0' shape=(10,) dtype=float32>, '0': <tf.Tensor '0:0' shape=(1, 1, 64, 64) dtype=float32>, '29': <tf.Tensor 'transpose_2:0' shape=(1, 8, 64, 64) dtype=float32>, '30': <tf.Tensor 'Relu:0' shape=(1, 8, 64, 64) dtype=float32>, '31': <tf.Tensor 'transpose_5:0' shape=(1, 16, 64, 64) dtype=float32>, '32': <tf.Tensor 'Relu_1:0' shape=(1, 16, 64, 64) dtype=float32>, '33': <tf.Tensor 'transpose_8:0' shape=(1, 32, 64, 64) dtype=float32>, '34': <tf.Tensor 'Relu_2:0' shape=(1, 32, 64, 64) dtype=float32>, '35': <tf.Tensor 'transpose_10:0' shape=(1, 32, 32, 32) dtype=float32>, '36': <tf.Tensor 'Relu_3:0' shape=(1, 32, 32, 32) dtype=float32>, '37': <tf.Tensor 'transpose_13:0' shape=(1, 40, 32, 32) dtype=float32>, '38': <tf.Tensor 'Relu_4:0' shape=(1, 40, 32, 32) dtype=float32>, '39': <tf.Tensor 'transpose_16:0' shape=(1, 48, 32, 32) dtype=float32>, '40': <tf.Tensor 'Relu_5:0' shape=(1, 48, 32, 32) dtype=float32>, '41': <tf.Tensor 'transpose_19:0' shape=(1, 64, 32, 32) dtype=float32>, '42': <tf.Tensor 'Relu_6:0' shape=(1, 64, 32, 32) dtype=float32>, '43': <tf.Tensor 'transpose_21:0' shape=(1, 64, 16, 16) dtype=float32>, '44': <tf.Tensor 'Relu_7:0' shape=(1, 64, 16, 16) dtype=float32>, '45': <tf.Tensor 'transpose_24:0' shape=(1, 72, 16, 16) dtype=float32>, '46': <tf.Tensor 'Relu_8:0' shape=(1, 72, 16, 16) dtype=float32>, '47': <tf.Tensor 'transpose_27:0' shape=(1, 80, 16, 16) dtype=float32>, '48': <tf.Tensor 'Relu_9:0' shape=(1, 80, 16, 16) dtype=float32>, '49': <tf.Tensor 'transpose_30:0' shape=(1, 96, 16, 16) dtype=float32>, '50': <tf.Tensor 'Relu_10:0' shape=(1, 96, 16, 16) dtype=float32>, '51': <tf.Tensor 'transpose_32:0' shape=(1, 96, 8, 8) dtype=float32>, '52': <tf.Tensor 'Relu_11:0' shape=(1, 96, 8, 8) dtype=float32>, '53': <tf.Tensor 'transpose_35:0' shape=(1, 128, 8, 8) dtype=float32>, '54': <tf.Tensor 'Relu_12:0' shape=(1, 128, 8, 8) dtype=float32>, '55': <tf.Tensor 'transpose_38:0' shape=(1, 192, 8, 8) dtype=float32>, '56': <tf.Tensor 'Relu_13:0' shape=(1, 192, 8, 8) dtype=float32>, '57': <tf.Tensor 'transpose_41:0' shape=(1, 256, 8, 8) dtype=float32>, '58': <tf.Tensor 'Relu_14:0' shape=(1, 256, 8, 8) dtype=float32>, '59': <tf.Tensor 'Mean:0' shape=(1, 256, 8) dtype=float32>, '60': <tf.Tensor 'Mean_1:0' shape=(1, 256) dtype=float32>, '61': <tf.Tensor 'add_12:0' shape=(1, 1024) dtype=float32>, '62': <tf.Tensor 'Relu_15:0' shape=(1, 1024) dtype=float32>, '63': <tf.Tensor 'add_13:0' shape=(1, 10) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "print(tf_rep.inputs) # Input nodes to the model\n",
    "print('-----')\n",
    "print(tf_rep.outputs) # Output nodes from the model\n",
    "print('-----')\n",
    "print(tf_rep.tensor_dict) # All nodes in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outputs(_0=array([[-0.02238697, -0.29960835, -0.03953697,  0.13984193, -0.0435295 ,\n",
       "         0.07639679, -0.10470795, -0.18059273, -0.0128672 , -0.29820734]],\n",
       "      dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_rep.run(np.random.randn(1,1,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Outputs(_0=array([[ -3.238375  ,  32.94328   ,  -6.1563983 , -18.473707  ,\n",
       "          -2.4727979 ,   0.27463698,  -1.5059704 , -14.4439945 ,\n",
       "         -26.715906  ,  -7.621884  ]], dtype=float32)), 'ZERO')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.expand_dims(np.expand_dims(np.asarray(img, dtype=np.float32), axis=0), axis=0)\n",
    "y = tf_rep.run(x)\n",
    "\n",
    "y, label_dict[np.argmax(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/tools/import_pb_to_tensorboard.py:56: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "Model Imported. Visualize by running: tensorboard --logdir=sl_log\n"
     ]
    }
   ],
   "source": [
    "tf_rep.export_graph(\"sign_lang_net.pb\")\n",
    "import_to_tensorboard(\"sign_lang_net.pb\", \"sl_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_tensor = 'import/0:0'\n",
    "out_tensor = 'import/add_13:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.238375    32.94328     -6.1563983  -18.473707    -2.4727979\n",
      "    0.27463698  -1.5059704  -14.4439945  -26.715906    -7.621884  ]] ZERO\n"
     ]
    }
   ],
   "source": [
    "with gfile.FastGFile(\"sign_lang_net.pb\", 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    with tf.Session() as sess:\n",
    "        sess.graph.as_default()\n",
    "        tf.import_graph_def(graph_def)\n",
    "        tf.global_variables_initializer().run()\n",
    "        sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "        \n",
    "        feed_dict = dict([(in_tensor, x)])\n",
    "        y = sess.run(out_tensor, feed_dict=feed_dict)\n",
    "        \n",
    "        print(y, label_dict[np.argmax(y)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move to Tensoflow Lite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_tensor = '0'\n",
    "out_tensor = 'add_13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5117180"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_def_file = \"sign_lang_net.pb\"\n",
    "input_arrays = [in_tensor]\n",
    "output_arrays = [out_tensor]\n",
    "\n",
    "converter = TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(\"sign_lang_net.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
